{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNN2fViIFf-F"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqbE0LJ21sSb"
      },
      "source": [
        "# **Intro to Generative Adversarial Networks (GANs)**\n",
        "\n",
        "Generative adversarial networks (GANs) are algorithmic architectures that use two neural networks, compitting one against the other (thus the “adversarial”) in order to generate new, synthetic instances of data that can pass for real data. They are used widely in image generation, video generation and voice generation.\n",
        "\n",
        "GANs were introduced in [a paper by Ian Goodfellow](https://arxiv.org/abs/1406.2661) and other researchers at the University of Montreal, including Yoshua Bengio, in 2014. Referring to GANs, Facebook’s AI research director Yann LeCun called adversarial training “the most interesting idea in the last 10 years in ML.”\n",
        "\n",
        "\n",
        "## **Some cool demos**:\n",
        "* Progress over the last several years, from [Ian Goodfellow tweet](https://twitter.com/goodfellow_ian/status/1084973596236144640)\n",
        "\n",
        "<img src='http://drive.google.com/uc?export=view&id=1PSfze4ZHgAn4BAjLuZhqAZO_HJQ1NEHX' width=1000 height=350/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOd3Y14aM5bD"
      },
      "source": [
        "A generative adversarial network (GAN) has two parts:\n",
        "\n",
        "* The **generator** learns to generate plausible data. The generated instances become negative training examples for the discriminator.\n",
        "* The **discriminator** learns to distinguish the generator's fake data from real data. The discriminator penalizes the generator for producing implausible results.\n",
        "\n",
        "\n",
        "When training begins, the generator produces obviously fake data, and the discriminator quickly learns to tell that it's fake:\n",
        "\n",
        "<img src='http://drive.google.com/uc?export=view&id=1Auxzsi3395vL0K80GfYlAEvWufTMTZ59' width=1000 height=350/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sdNCH5Jx1JQ"
      },
      "source": [
        "# **<font color='Darkblue'>Import Required Libraries:</font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5cL9HOPx0Ba"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "#%matplotlib inline\n",
        "import random\n",
        "import torch\n",
        "from torch import nn\n",
        "from tqdm.auto import tqdm\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets # Training dataset\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision import utils\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "\n",
        "\n",
        "# Decide which device we want to run on\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"My device: => \", device)\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "my_seed = 123\n",
        "random.seed(my_seed)\n",
        "torch.manual_seed(my_seed);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bn1eTo8E47yn"
      },
      "source": [
        "# **Fashion-MNIST Dataset:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWFDggIm47RU"
      },
      "source": [
        "`Fashion-MNIST` is a dataset of [Zalando](https://jobs.zalando.com/en/tech/?gh_src=281f2ef41us)'s article images—consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. We intend Fashion-MNIST to serve as a direct drop-in replacement for the original [MNIST dataset](http://yann.lecun.com/exdb/mnist/) for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.\n",
        "\n",
        "<img src='https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/doc/img/fashion-mnist-sprite.png' width=1000 height=700/>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJQG4r0bpL7f"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "data_train = datasets.FashionMNIST('./data', download=True, train=True, transform=transform)\n",
        "train_loader = DataLoader(data_train, batch_size=batch_size, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O09v4JRepEpb"
      },
      "outputs": [],
      "source": [
        "classes = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle Boot']\n",
        "\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "images_arr = []\n",
        "labels_arr = []\n",
        "\n",
        "for i in range(0, 30):\n",
        "  images_arr.append(images[i].unsqueeze(0))\n",
        "  labels_arr.append(labels[i].item())\n",
        "\n",
        "fig = plt.figure(figsize=(25, 10))\n",
        "for i in range(30):\n",
        "  ax = fig. add_subplot(3, 10, i+1, xticks=[], yticks=[])\n",
        "  ax.imshow(images_arr[i].resize_(1, 28, 28).numpy().squeeze(), cmap='gray')\n",
        "  ax.set_title(\"{}\".format(classes[labels_arr[i]]), color=(\"blue\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmMi8DzUy9AB"
      },
      "source": [
        "# **<font color='darkorange'>Generator Part:</font>**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0oHVKHjNFU8"
      },
      "source": [
        "The generator part of a GAN learns to create fake data by incorporating feedback from the discriminator. It learns to make the discriminator classify its output as real.\n",
        "\n",
        "Generator training requires tighter integration between the generator and the discriminator than discriminator training requires. The portion of the GAN that trains the generator includes:\n",
        "\n",
        "\n",
        "\n",
        "*   random input\n",
        "*   generator network, which transforms the random input into a data instance\n",
        "*   discriminator network, which classifies the generated data\n",
        "*   discriminator output\n",
        "*   generator loss, which penalizes the generator for failing to fool the discriminator\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<img src='http://drive.google.com/uc?export=view&id=1dbk5FmAHE3LHwspYm8qxL-qHBLXBq29i' width=1000 height=350/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oiv2UHdd6eFJ"
      },
      "source": [
        "### **Generator Block:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59iLl2LwzRwp"
      },
      "outputs": [],
      "source": [
        "def get_generator_block(input_dim, output_dim):\n",
        "  seq = nn.Sequential(\n",
        "      nn.Linear(input_dim, output_dim),\n",
        "      nn.BatchNorm1d(output_dim),\n",
        "      nn.LeakyReLU(negative_slope=0.2, inplace=False),\n",
        "      nn.Dropout(0.3),\n",
        "  )\n",
        "  return seq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7-OxJAD6vZg"
      },
      "source": [
        "### **Generator Class:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kqlGdVG6tJf"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, z_dim=10, img_dim=28*28, hidden_dim=128):\n",
        "    super(Generator, self).__init__()\n",
        "\n",
        "    self.gen = nn.Sequential(\n",
        "        get_generator_block(z_dim, hidden_dim),\n",
        "        get_generator_block(hidden_dim, hidden_dim * 2),\n",
        "        get_generator_block(hidden_dim * 2, hidden_dim * 4),\n",
        "        get_generator_block(hidden_dim * 4, hidden_dim * 8),\n",
        "        nn.Linear(hidden_dim * 8, img_dim),\n",
        "        nn.Sigmoid(),\n",
        "    )\n",
        "\n",
        "  def forward(self, noise):\n",
        "    gen_output = self.gen(noise)\n",
        "    return gen_output\n",
        "\n",
        "\n",
        "      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nx0q1MXVuYy4"
      },
      "outputs": [],
      "source": [
        "# Generate Noise:\n",
        "\n",
        "def get_generator_noise(n_sample, z_dim, device='cpu'):\n",
        "  my_noise = torch.randn(n_sample, z_dim, device=device)\n",
        "  return my_noise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2LvZp7WzO-k"
      },
      "source": [
        "# **<font color='darkorange'>Discriminator Part:</font>**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qTLijtmNItI"
      },
      "source": [
        "The discriminator in a GAN is simply a classifier. It tries to distinguish real data from the data created by the generator. It could use any network architecture appropriate to the type of data it's classifying.\n",
        "\n",
        "The discriminator's training data comes from two sources:\n",
        "\n",
        "* **Real data** instances, such as real pictures of people. The discriminator uses these instances as positive examples during training.\n",
        "* **Fake data** instances created by the generator. The discriminator uses these instances as negative examples during training.\n",
        "\n",
        "<img src='http://drive.google.com/uc?export=view&id=1A3_gYqcPORqXFio1wNHAsc8ZndY3zpIP' width=1000 height=350/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "icimYWcnynYo"
      },
      "outputs": [],
      "source": [
        "# Discriminator Block\n",
        "\n",
        "def get_discriminator_block(input_dim, output_dim):\n",
        "  seq = nn.Sequential(\n",
        "      nn.Linear(input_dim, output_dim),\n",
        "      nn.LeakyReLU(negative_slope=0.2, inplace=False),\n",
        "  )\n",
        "  return seq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbvL68C3UnBe"
      },
      "source": [
        "<img src='https://miro.medium.com/max/1400/1*siH_yCvYJ9rqWSUYeDBiRA.png' width=800 height=400/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFZzJ6Ykktoj"
      },
      "outputs": [],
      "source": [
        "# Discriminator Class:\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, img_dim=28*28, hidden_dim=128):\n",
        "    super(Discriminator, self).__init__()\n",
        "\n",
        "    self.disc = nn.Sequential(\n",
        "        get_discriminator_block(img_dim, hidden_dim * 4),\n",
        "        get_discriminator_block(hidden_dim * 4, hidden_dim * 2),\n",
        "        get_discriminator_block(hidden_dim * 2, hidden_dim),\n",
        "        nn.Linear(hidden_dim, 1),\n",
        "    )\n",
        "\n",
        "  def forward(self, image):\n",
        "    state = self.disc(image)\n",
        "    return state\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSPEIaEzzSSi"
      },
      "source": [
        "# **<font color='deepskyblue'>Training Process:</font>**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tV4vhVGBNOpV"
      },
      "source": [
        "Because a GAN contains two separately trained networks, its training algorithm must address two complications:\n",
        "\n",
        "* GANs must juggle two different kinds of training (generator and discriminator).\n",
        "* GAN convergence is hard to identify."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHRul4rxtZtY"
      },
      "source": [
        "### **Set Hyperparameters:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAcJKanPz2k_"
      },
      "outputs": [],
      "source": [
        "# Set your parameters\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "num_epochs = 51\n",
        "z_dim = 64\n",
        "display_step = 100\n",
        "lr = 0.0001\n",
        "\n",
        "size = (1, 28, 28)\n",
        "\n",
        "device = 'cuda'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Em4LRmZCtwgD"
      },
      "outputs": [],
      "source": [
        "# Generator:\n",
        "generator = Generator(z_dim).to(device)\n",
        "gen_optimizer = torch.optim.Adam(generator.parameters(), lr=lr)\n",
        "\n",
        "# Discriminator:\n",
        "discriminator = Discriminator().to(device)\n",
        "disc_optimizer = torch.optim.Adam(discriminator.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-QwiEmVt-5Q"
      },
      "outputs": [],
      "source": [
        "# Discriminator Loss:\n",
        "\n",
        "def get_discriminator_loss(gen, disc, criterion, real, num_images, z_dim, device):\n",
        "  noise = get_generator_noise(num_images, z_dim, device=device)\n",
        "  gen_output = gen(noise)\n",
        "  disc_out_fake = disc(gen_output.detach())\n",
        "  disc_loss_fake = criterion(disc_out_fake, torch.zeros_like(disc_out_fake))\n",
        "  disc_out_real = disc(real)\n",
        "  disc_loss_real = criterion(disc_out_real, torch.ones_like(disc_out_real))\n",
        "\n",
        "  disc_loss = (disc_loss_fake + disc_loss_real) / 2\n",
        "  return disc_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_p0cZWuuyTa"
      },
      "outputs": [],
      "source": [
        "# Generator Loss:\n",
        "def get_generator_loss(gen, disc, criterion, num_images, z_dim, device):\n",
        "  noise = get_generator_noise(num_images, z_dim, device=device)\n",
        "  gen_output = gen(noise)\n",
        "  disc_preds = disc(gen_output) # gen_output.detach()\n",
        "  gen_loss = criterion(disc_preds, torch.ones_like(disc_preds))\n",
        "\n",
        "  return gen_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C06QBAlavhe-"
      },
      "outputs": [],
      "source": [
        "# Show Images Function:\n",
        "\n",
        "def show_tensor_images(real, fake, num_images=25, size=(1, 28, 28)):\n",
        "  plt.figure(figsize=(15,15))\n",
        "  image_unflat_real = real.detach().cpu().view(-1, *size)\n",
        "  image_grid_real = make_grid(image_unflat_real[:num_images], nrow=5, normalize=True, padding=2)\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.axis(\"off\")\n",
        "  plt.title(\"Real Images\")\n",
        "  plt.imshow(image_grid_real.permute(1, 2, 0).squeeze())\n",
        "\n",
        "  image_unflat_fake = fake.detach().cpu().view(-1, *size)\n",
        "  image_grid_fake = make_grid(image_unflat_fake[:num_images], nrow=5, normalize=True, padding=2)\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.axis(\"off\")\n",
        "  plt.title(\"Fake Images\")\n",
        "  plt.imshow(image_grid_fake.permute(1, 2, 0).squeeze())\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNdismSCvUTY"
      },
      "outputs": [],
      "source": [
        "# Training Loop\n",
        "\n",
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "\n",
        "iters = 0\n",
        "cur_step = 0\n",
        "img_show = 3\n",
        "\n",
        "mean_generator_loss = 0\n",
        "mean_discriminator_loss = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "  for real, _ in tqdm(train_loader):\n",
        "    cur_batch_size = len(real)\n",
        "\n",
        "    real = real.view(cur_batch_size, -1).to(device)\n",
        "\n",
        "    disc_optimizer.zero_grad()\n",
        "\n",
        "    disc_loss = get_discriminator_loss(generator, discriminator, criterion, real, cur_batch_size, z_dim, device)\n",
        "\n",
        "    disc_loss.backward()\n",
        "\n",
        "    disc_optimizer.step()\n",
        "\n",
        "\n",
        "    gen_optimizer.zero_grad()\n",
        "    gen_loss = get_generator_loss(generator, discriminator, criterion, cur_batch_size, z_dim, device)\n",
        "    gen_loss.backward()\n",
        "    gen_optimizer.step()\n",
        "\n",
        "    mean_discriminator_loss += disc_loss.item() / cur_batch_size\n",
        "    mean_generator_loss += gen_loss.item() / cur_batch_size\n",
        "\n",
        "    G_losses.append(mean_discriminator_loss)\n",
        "    D_losses.append(mean_generator_loss)\n",
        "\n",
        "\n",
        "    if cur_step % display_step == 0 and cur_step >= 0:\n",
        "      print(f\"[Epoch: {epoch}/{num_epochs}] | [Step: {cur_step}/{num_epochs*len(train_loader)}], Generator Loss: {mean_generator_loss}, Discriminator Loss: {mean_discriminator_loss}\")\n",
        "      fake_noise = get_generator_noise(cur_batch_size, z_dim, device=device)\n",
        "      fake = generator(fake_noise)\n",
        "\n",
        "      img_list.append(make_grid(fake.detach().cpu().view(-1, *size)[:36], nrow=6, normalize=True, padding=2))\n",
        "      mean_discriminator_loss = 0\n",
        "      mean_generator_loss = 0\n",
        "\n",
        "    cur_step += 1\n",
        "\n",
        "  if epoch % img_show == 0:\n",
        "    fake_noise = get_generator_noise(cur_batch_size, z_dim, device=device)\n",
        "    fake = generator(fake_noise)\n",
        "    show_tensor_images(real, fake)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Visualization:**"
      ],
      "metadata": {
        "id": "KnPy-csflvcM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kebd6zxRHVcz"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 7))\n",
        "plt.title(\"Generator and Discriminator Loss During Training\")\n",
        "plt.plot(G_losses, label=\"Generator\")\n",
        "plt.plot(D_losses, label=\"Discriminator\")\n",
        "plt.xlabel(\"steps\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(8, 8))\n",
        "plt.axis(\"off\")\n",
        "imgs = [[plt.imshow(np.transpose(img, (1,2,0)), animated=True)] for img in img_list]\n",
        "anim = animation.ArtistAnimation(fig, imgs, interval=100, repeat_delay=1000, blit=True)\n",
        "\n",
        "HTML(anim.to_jshtml())"
      ],
      "metadata": {
        "id": "Ti-r0eXvv0im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3COkXQEAc42-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "GAN_PyTorch_HandsOn_Final.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}